{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import *\n",
    "import glob\n",
    "from keras.layers import Activation, Conv2D, Dropout, MaxPooling2D, Flatten, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dict_with_params(path):\n",
    "    param_list = open(path, 'r').read().split('\\n')\n",
    "    param_list = list(map(lambda x: x.split(\" = \"), param_list))\n",
    "    d = {x[0]:x[1] for x in param_list}\n",
    "    int_params = ['batch_size', 'epochs', 'img_height', 'img_width',\n",
    "                  'nb_train_samples', 'nb_validation_samples']\n",
    "    for param in int_params:\n",
    "        d[param] = int(d[param])\n",
    "    d['without_augmentation'] = str_to_bool(d['without_augmentation'])\n",
    "    if not d['without_augmentation']:\n",
    "        gen_params = d['generator_params'][1:-1].split(\",\")\n",
    "        new_d = {}\n",
    "        for param in gen_params:\n",
    "            key, value = param.split(\" : \")\n",
    "            new_d[key.strip()] = value\n",
    "        gen_float_params  = ['height_shift_range', 'rotation_range',\n",
    "                             'shear_range', 'width_shift_range', 'zoom_range']\n",
    "        for param in gen_float_params:\n",
    "            new_d[param] = float(new_d[param])\n",
    "        new_d['horizontal_flip'] = str_to_bool(new_d['horizontal_flip'])\n",
    "        d['generator_params'] = new_d\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_to_bool(s):\n",
    "    if s == 'True':\n",
    "         return True\n",
    "    elif s == 'False':\n",
    "         return False\n",
    "    else:\n",
    "         raise ValueError(\"Cannot covert {} to a bool\".format(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## images size reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(data_path, rows, cols, img_type = \"jpg\"):\n",
    "    imgs = glob.glob(data_path + \"\\\\*\" + img_type)\n",
    "    img_count = len(imgs)\n",
    "    imgs_data = np.ndarray((img_count, rows, cols, 3), dtype = np.uint8)\n",
    "    for i in range(img_count):\n",
    "        imgs_data[i, :, :] =  mpimg.imread(imgs[i])\n",
    "    return imgs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def size_reduction(data, path, img_type = \"jpg\"):\n",
    "    i = 1\n",
    "    for img in data:\n",
    "        im = Image.fromarray(img[128:-128,128:-128])\n",
    "        im.save(path + str(i) + \".\" + img_type)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_mask(path, mask_path, rows, cols, save_path, img_type = \"jpg\"):\n",
    "    imgs = load_data(path, rows, cols, img_type)\n",
    "    masks = load_data(mask_path, rows, cols, img_type)\n",
    "    imgs = imgs.astype('float32')\n",
    "    masks = masks.astype('float32')\n",
    "    imgs /= 255\n",
    "    masks /= 255\n",
    "    masks[masks > 0.5] = 1\n",
    "    masks[masks <= 0.5] = 0\n",
    "    i = 1\n",
    "    res = imgs * masks\n",
    "    for img in res:\n",
    "        print(img.shape)\n",
    "        img = img * 255\n",
    "        img = img.astype('uint8')\n",
    "        img = Image.fromarray(img)\n",
    "        img.save(save_path + str(i) + \".\" + img_type)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_path_0 = \"data/with_masks/0_512\"\n",
    "out_path_0 = \"data/with_masks/0_256/\"\n",
    "img_width = 512\n",
    "img_height = 512 \n",
    "\n",
    "data = load_data(inp_path_0, img_width, img_height)\n",
    "size_reduction(data, out_path_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_path_1 = \"data/with_masks/1_512\"\n",
    "out_path_1 = \"data/with_masks/1_256/\"\n",
    "img_width = 512\n",
    "img_height = 512 \n",
    "\n",
    "data = load_data(inp_path_1, img_width, img_height)\n",
    "size_reduction(data, out_path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_path_0 = \"data/with_masks/0_256\"\n",
    "mask_path_0 = \"data/with_masks/masks_0/\"\n",
    "save_path_0 = \"data/with_masks/result_0/\"\n",
    "\n",
    "img_path_1 = \"data/with_masks/1_256\"\n",
    "mask_path_1 = \"data/with_masks/masks_1/\"\n",
    "save_path_1 = \"data/with_masks/result_1/\"\n",
    "\n",
    "img_width = 256\n",
    "img_height = 256 \n",
    "\n",
    "apply_mask(img_path_0, mask_path_0, img_width, img_height, save_path_0, img_type = \"jpg\")\n",
    "apply_mask(img_path_1, mask_path_1, img_width, img_height, save_path_1, img_type = \"jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plots(ims, figsize=(12, 6), rows = 1):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0, 2, 3, 1))\n",
    "    f = plt.figure(figsize = figsize)\n",
    "    cols = len(ims) // rows if len(ims) % 2 == 0 else len(ims) // rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        plt.imshow(ims[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_generator(data_dir, batch_size, img_width, img_height,\n",
    "                     rotation_range = 0, width_shift_range = 0,\n",
    "                     height_shift_range = 0, shear_range = 0,\n",
    "                     zoom_range = 0, horizontal_flip = False):\n",
    "    \n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale = 1./255, rotation_range = rotation_range, width_shift_range = width_shift_range,\n",
    "        height_shift_range = height_shift_range, shear_range = shear_range, zoom_range = zoom_range,\n",
    "        horizontal_flip = horizontal_flip)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        data_dir, target_size = (img_width, img_height),\n",
    "        batch_size = batch_size, class_mode = 'binary')\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data augmentation example\n",
    "cfg_name = \"cfg1.txt\"\n",
    "d = create_dict_with_params(\"cfg/\" + cfg_name)\n",
    "train_generator = create_generator(**d, **d[\"generator_params\"])\n",
    "aug_images = [next(train_generator)[0][0] for i in range(10)]\n",
    "plots(aug_images, figsize=(20,7), rows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(img_width, img_height):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, 11 ,activation = 'relu', input_shape = (img_width, img_height, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "\n",
    "    model.add(Conv2D(64, 3 ,activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, 3 ,activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, 3 ,activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "        optimizer='rmsprop',\n",
    "        metrics=['accuracy', recall_threshold()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_logs(path, name, cfg_name, evaluation):\n",
    "    info = \"cfg name = \" + cfg_name + \"\\n\"\n",
    "    for x in evaluation:\n",
    "        info += (x[0] + \" : \" + str(x[1]) + \"\\n\")\n",
    "    with open(path + \"/\" + name + \".txt\", 'w') as out:\n",
    "        out.write(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main(cfg_name, img_width, img_height, train_data_dir, validation_data_dir,\n",
    "         nb_train_samples, result_name, nb_validation_samples, epochs, batch_size,\n",
    "         without_augmentation, generator_params = None):\n",
    "    \n",
    "    model = get_model(img_width, img_height)\n",
    "\n",
    "    if without_augmentation:\n",
    "        train_generator = create_generator(train_data_dir, batch_size,\n",
    "                                           img_width, img_height)\n",
    "    else:\n",
    "        train_generator = create_generator(train_data_dir, batch_size,\n",
    "                                           img_width, img_height, **generator_params)\n",
    "\n",
    "    validation_generator = create_generator(validation_data_dir, batch_size, img_width, img_height)\n",
    "\n",
    "    model.fit_generator(\n",
    "            train_generator, steps_per_epoch = nb_train_samples // batch_size,\n",
    "            epochs = epochs, validation_data = validation_generator,\n",
    "            validation_steps = nb_validation_samples // batch_size)\n",
    "    \n",
    "    evaluation = list(zip(model.metrics_names, model.evaluate_generator(validation_generator,\n",
    "                                                          nb_validation_samples / batch_size)))\n",
    "    create_logs(\"results\", result_name, cfg_name, evaluation)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 182 images belonging to 2 classes.\n",
      "Found 48 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "91/91 [==============================] - 62s 681ms/step - loss: 1.2983 - acc: 0.6374 - recall: 0.0989 - val_loss: 0.6762 - val_acc: 0.7083 - val_recall: 0.2500\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 60s 664ms/step - loss: 0.7706 - acc: 0.7637 - recall: 0.3407 - val_loss: 0.4628 - val_acc: 0.7708 - val_recall: 0.5833\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 61s 672ms/step - loss: 0.5051 - acc: 0.8242 - recall: 0.4341 - val_loss: 0.3883 - val_acc: 0.8125 - val_recall: 0.7500\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 60s 657ms/step - loss: 0.3110 - acc: 0.8791 - recall: 0.4890 - val_loss: 0.5875 - val_acc: 0.7500 - val_recall: 0.7500\n",
      "Epoch 5/15\n",
      "91/91 [==============================] - 60s 664ms/step - loss: 0.3337 - acc: 0.9066 - recall: 0.5604 - val_loss: 0.1847 - val_acc: 0.9375 - val_recall: 0.7500\n",
      "Epoch 6/15\n",
      "91/91 [==============================] - 62s 678ms/step - loss: 0.2567 - acc: 0.9286 - recall: 0.5604 - val_loss: 0.2118 - val_acc: 0.8750 - val_recall: 0.6667\n",
      "Epoch 7/15\n",
      "91/91 [==============================] - 62s 676ms/step - loss: 0.2344 - acc: 0.9396 - recall: 0.5714 - val_loss: 2.0715 - val_acc: 0.8333 - val_recall: 0.4792\n",
      "Epoch 8/15\n",
      "91/91 [==============================] - 62s 682ms/step - loss: 0.2184 - acc: 0.9451 - recall: 0.5659 - val_loss: 0.2536 - val_acc: 0.8750 - val_recall: 0.6250\n",
      "Epoch 9/15\n",
      "91/91 [==============================] - 63s 688ms/step - loss: 0.2210 - acc: 0.9560 - recall: 0.5385 - val_loss: 0.8753 - val_acc: 0.8750 - val_recall: 0.6875\n",
      "Epoch 10/15\n",
      "91/91 [==============================] - 61s 674ms/step - loss: 0.3133 - acc: 0.9615 - recall: 0.5934 - val_loss: 0.1619 - val_acc: 0.9375 - val_recall: 0.7083\n",
      "Epoch 11/15\n",
      "91/91 [==============================] - 61s 670ms/step - loss: 0.1644 - acc: 0.9780 - recall: 0.5934 - val_loss: 0.3092 - val_acc: 0.8958 - val_recall: 0.7500\n",
      "Epoch 12/15\n",
      "91/91 [==============================] - 64s 703ms/step - loss: 0.1260 - acc: 0.9560 - recall: 0.5549 - val_loss: 0.1712 - val_acc: 0.8958 - val_recall: 0.5625\n",
      "Epoch 13/15\n",
      "91/91 [==============================] - 64s 704ms/step - loss: 0.0879 - acc: 0.9725 - recall: 0.5769 - val_loss: 0.4679 - val_acc: 0.8750 - val_recall: 0.6458\n",
      "Epoch 14/15\n",
      "91/91 [==============================] - 63s 689ms/step - loss: 0.4035 - acc: 0.9670 - recall: 0.5714 - val_loss: 0.8555 - val_acc: 0.9375 - val_recall: 0.6667\n",
      "Epoch 15/15\n",
      "91/91 [==============================] - 63s 697ms/step - loss: 0.1771 - acc: 0.9560 - recall: 0.5440 - val_loss: 0.4282 - val_acc: 0.8750 - val_recall: 0.7500\n"
     ]
    }
   ],
   "source": [
    "cfg_name = \"cfg3.txt\"\n",
    "d = create_dict_with_params(\"cfg/\" + cfg_name)\n",
    "model = main(cfg_name = cfg_name, **d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"results/weights3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recall_threshold(threshold = 0.5):\n",
    "    def recall(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.clip(y_true, 0, 1))\n",
    "        recall_ratio = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall_ratio\n",
    "    return recall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
