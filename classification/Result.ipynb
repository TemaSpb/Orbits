{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import *\n",
    "import glob\n",
    "from keras.layers import Activation, Conv2D, Dropout, MaxPooling2D, Flatten, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plots(ims, figsize=(12, 6), rows = 1):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0, 2, 3, 1))\n",
    "    f = plt.figure(figsize = figsize)\n",
    "    cols = len(ims) // rows if len(ims) % 2 == 0 else len(ims) // rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        plt.imshow(ims[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_generator(data_dir, batch_size, img_width, img_height,\n",
    "                     rotation_range = 0, width_shift_range = 0,\n",
    "                     height_shift_range = 0, shear_range = 0,\n",
    "                     zoom_range = 0, horizontal_flip = False):\n",
    "    \n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale = 1./255, rotation_range = rotation_range, width_shift_range = width_shift_range,\n",
    "        height_shift_range = height_shift_range, shear_range = shear_range, zoom_range = zoom_range,\n",
    "        horizontal_flip = horizontal_flip)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        data_dir, target_size = (img_width, img_height),\n",
    "        batch_size = batch_size, class_mode = 'binary')\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Системе не удается найти указанный путь: 'dataset_classification/2/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-2d6229ff27d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# data augmentation example\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m train_generator = create_generator(train_data_dir, batch_size,\n\u001b[1;32m----> 3\u001b[1;33m                                        img_width, img_height, **generator_params)\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0maug_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maug_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-7885ddbe5a86>\u001b[0m in \u001b[0;36mcreate_generator\u001b[1;34m(data_dir, batch_size, img_width, img_height, rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip)\u001b[0m\n\u001b[0;32m     11\u001b[0m     generator = datagen.flow_from_directory(\n\u001b[0;32m     12\u001b[0m         \u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         batch_size = batch_size, class_mode = 'binary')\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             interpolation=interpolation)\n\u001b[0m\u001b[0;32m    759\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[0;32m   1363\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Системе не удается найти указанный путь: 'dataset_classification/2/train'"
     ]
    }
   ],
   "source": [
    "# data augmentation example\n",
    "train_generator = create_generator(train_data_dir, batch_size,\n",
    "                                       img_width, img_height, **generator_params)\n",
    "aug_images = [next(train_generator)[0][0] for i in range(10)]\n",
    "plots(aug_images, figsize=(20,7), rows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(img_width, img_height):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, 11 ,activation = 'relu', input_shape = (img_width, img_height, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "\n",
    "    model.add(Conv2D(64, 3 ,activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, 3 ,activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, 3 ,activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "        optimizer='rmsprop',\n",
    "        metrics=['accuracy', recall_threshold(0.8)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_logs(path, name, accuracy, img_width, img_height,\n",
    "                epochs, batch_size, data_augmentation = False):\n",
    "    info = (\"number of epochs = {epochs}\" + \"\\nbatch_size = \" +\n",
    "            str(batch_size) + \"\\nimage size = (\" + str(img_width) + \",\" +\n",
    "            str(img_height) + \")\\n\" + \"data augmentation = \" +\n",
    "            str(data_augmentation) + \"\\naccuracy = \" + str(accuracy) + \"\\n\")\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    for metric in evaluation:\\n        info += metric + \" : \"\\n    with open(path + \"/\" + name + \".txt\" , \"w\") as text_file:\\n        text_file.write(info)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"    for metric in evaluation:\n",
    "        info += metric + \" : \"\n",
    "    with open(path + \"/\" + name + \".txt\" , \"w\") as text_file:\n",
    "        text_file.write(info)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of epochs = {epochs}\n",
      "batch_size = 4\n",
      "image size = (256,256)\n",
      "data augmentation = False\n",
      "accuracy = 3.123123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(create_logs(\"Asd\", \"Asd\", 3.123123, img_width, img_height,\n",
    "                epochs, batch_size, data_augmentation = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.22579369739426625, 0.9166666666666666]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(validation_generator, nb_validation_samples/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width = 512\n",
    "img_height = 512\n",
    "\n",
    "train_data_dir = 'dataset_classification/1/train'\n",
    "validation_data_dir = 'dataset_classification/1/validation'\n",
    "nb_train_samples = 182 #1160  \n",
    "nb_validation_samples = 48 #370\n",
    "epochs = 40\n",
    "batch_size = 4\n",
    "without_augmentation = True\n",
    "generator_params = {\"rotation_range\" : 10, \"width_shift_range\" : 0.2,\n",
    "                    \"height_shift_range\" : 0.2, \"shear_range\" : 0.2,\n",
    "                    \"zoom_range\" : 0.3, \"horizontal_flip\" : True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width = 256\n",
    "img_height = 256\n",
    "\n",
    "train_data_dir = 'data/256/train'\n",
    "validation_data_dir = 'data/256/validation'\n",
    "nb_train_samples = 182# 1160  \n",
    "nb_validation_samples = 48#370\n",
    "epochs = 5\n",
    "batch_size = 4\n",
    "without_augmentation = True\n",
    "generator_params = {\"rotation_range\" : 5, \"width_shift_range\" : 0.1,\n",
    "                    \"height_shift_range\" : 0.1, \"shear_range\" : 0.1,\n",
    "                    \"zoom_range\" : 0.2, \"horizontal_flip\" : True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 182 images belonging to 2 classes.\n",
      "Found 48 images belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "45/45 [==============================] - 53s 1s/step - loss: 1.5017 - acc: 0.6500 - recall: 0.0222 - val_loss: 0.6718 - val_acc: 0.5417 - val_recall: 0.0000e+00\n",
      "Epoch 2/5\n",
      "45/45 [==============================] - 53s 1s/step - loss: 0.6410 - acc: 0.7334 - recall: 0.1260 - val_loss: 0.6836 - val_acc: 0.6667 - val_recall: 0.5625\n",
      "Epoch 3/5\n",
      "45/45 [==============================] - 53s 1s/step - loss: 0.3951 - acc: 0.8333 - recall: 0.3779 - val_loss: 0.1802 - val_acc: 0.9167 - val_recall: 0.5000\n",
      "Epoch 4/5\n",
      "45/45 [==============================] - 53s 1s/step - loss: 0.3373 - acc: 0.9055 - recall: 0.4149 - val_loss: 0.2590 - val_acc: 0.8542 - val_recall: 0.7222\n",
      "Epoch 5/5\n",
      "45/45 [==============================] - 53s 1s/step - loss: 0.1883 - acc: 0.9111 - recall: 0.5816 - val_loss: 0.3145 - val_acc: 0.8750 - val_recall: 0.7222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x202093accc0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(img_width, img_height)\n",
    "\n",
    "if without_augmentation:\n",
    "    train_generator = create_generator(train_data_dir, batch_size,\n",
    "                                       img_width, img_height)\n",
    "else:\n",
    "    train_generator = create_generator(train_data_dir, batch_size,\n",
    "                                       img_width, img_height, **generator_params)\n",
    "    \n",
    "validation_generator = create_generator(validation_data_dir, batch_size, img_width, img_height)\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator, steps_per_epoch = nb_train_samples // batch_size,\n",
    "        epochs = epochs, validation_data = validation_generator,\n",
    "        validation_steps = nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recall_threshold(threshold = 0.5):\n",
    "    def recall(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.clip(y_true, 0, 1))\n",
    "        recall_ratio = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall_ratio\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dict_with_params(path):\n",
    "    param_list = open(path, 'r').read().split('\\n')\n",
    "    param_list = list(map(lambda x: x.split(\" = \"), param_list))\n",
    "    d = {x[0]:x[1] for x in param_list}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': '4',\n",
       " 'epochs': '30',\n",
       " 'generator_params': '{rotation_range : 5, width_shift_range : 0.1, height_shift_range : 0.1, shear_range : 0.1, zoom_range : 0.2, horizontal_flip : True}',\n",
       " 'img_height': '256',\n",
       " 'img_width': '256',\n",
       " 'nb_train_samples': '500',\n",
       " 'nb_validation_samples': '48',\n",
       " 'train_data_dir': 'data/256/train',\n",
       " 'validation_data_dir': 'data/256/validation',\n",
       " 'without_augmentation': 'False'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_dict_with_params(\"cfg/cfg4.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
