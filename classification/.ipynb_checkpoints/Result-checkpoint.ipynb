{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import *\n",
    "import glob\n",
    "from keras.layers import Activation, Conv2D, Dropout, MaxPooling2D, Flatten, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plots(ims, figsize=(12, 6), rows = 1):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0, 2, 3, 1))\n",
    "    f = plt.figure(figsize = figsize)\n",
    "    cols = len(ims) // rows if len(ims) % 2 == 0 else len(ims) // rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        plt.imshow(ims[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_generator(data_dir, batch_size, img_width, img_height,\n",
    "                     rotation_range = 0, width_shift_range = 0,\n",
    "                     height_shift_range = 0, shear_range = 0,\n",
    "                     zoom_range = 0, horizontal_flip = False):\n",
    "    \n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale = 1./255, rotation_range = rotation_range, width_shift_range = width_shift_range,\n",
    "        height_shift_range = height_shift_range, shear_range = shear_range, zoom_range = zoom_range,\n",
    "        horizontal_flip = horizontal_flip)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        data_dir, target_size = (img_width, img_height),\n",
    "        batch_size = batch_size, class_mode = 'binary')\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_to_bool(s):\n",
    "    if s == 'True':\n",
    "         return True\n",
    "    elif s == 'False':\n",
    "         return False\n",
    "    else:\n",
    "         raise ValueError(\"Cannot covert {} to a bool\".format(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data augmentation example\n",
    "train_generator = create_generator(train_data_dir, batch_size,\n",
    "                                       img_width, img_height, **generator_params)\n",
    "aug_images = [next(train_generator)[0][0] for i in range(10)]\n",
    "plots(aug_images, figsize=(20,7), rows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(img_width, img_height):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, 11 ,activation = 'relu', input_shape = (img_width, img_height, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "\n",
    "    model.add(Conv2D(64, 3 ,activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, 3 ,activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, 3 ,activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "        optimizer='rmsprop',\n",
    "        metrics=['accuracy', recall_threshold()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_logs(path, name, cfg_name, evaluation):\n",
    "    info = \"cfg name = \" + cfg_name + \"\\n\"\n",
    "    for x in evaluation:\n",
    "        info += (x[0] + \" : \" + str(x[1]) + \"\\n\")\n",
    "    with open(path + \"/\" + name + \".txt\", 'w') as out:\n",
    "        out.write(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main(cfg_name, img_width, img_height, train_data_dir, validation_data_dir,\n",
    "         nb_train_samples, result_name, nb_validation_samples, epochs, batch_size,\n",
    "         without_augmentation, generator_params = None):\n",
    "    \n",
    "    model = get_model(img_width, img_height)\n",
    "\n",
    "    if without_augmentation:\n",
    "        train_generator = create_generator(train_data_dir, batch_size,\n",
    "                                           img_width, img_height)\n",
    "    else:\n",
    "        train_generator = create_generator(train_data_dir, batch_size,\n",
    "                                           img_width, img_height, **generator_params)\n",
    "\n",
    "    validation_generator = create_generator(validation_data_dir, batch_size, img_width, img_height)\n",
    "\n",
    "    model.fit_generator(\n",
    "            train_generator, steps_per_epoch = nb_train_samples // batch_size,\n",
    "            epochs = epochs, validation_data = validation_generator,\n",
    "            validation_steps = nb_validation_samples // batch_size)\n",
    "    \n",
    "    evaluation = list(zip(model.metrics_names, model.evaluate_generator(validation_generator,\n",
    "                                                          nb_validation_samples / batch_size)))\n",
    "    create_logs(\"results\", result_name, cfg_name, evaluation)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 182 images belonging to 2 classes.\n",
      "Found 48 images belonging to 2 classes.\n",
      "Epoch 1/40\n",
      "45/45 [==============================] - 148s 3s/step - loss: 4.0339 - acc: 0.6056 - recall: 0.0000e+00 - val_loss: 0.6865 - val_acc: 0.5417 - val_recall: 0.0000e+00\n",
      "Epoch 2/40\n",
      "45/45 [==============================] - 149s 3s/step - loss: 0.7323 - acc: 0.6724 - recall: 0.2038 - val_loss: 0.6660 - val_acc: 0.5833 - val_recall: 0.2917\n",
      "Epoch 3/40\n",
      "45/45 [==============================] - 148s 3s/step - loss: 0.6579 - acc: 0.7278 - recall: 0.3519 - val_loss: 0.6351 - val_acc: 0.6250 - val_recall: 0.5000\n",
      "Epoch 4/40\n",
      "45/45 [==============================] - 148s 3s/step - loss: 0.5423 - acc: 0.7944 - recall: 0.6335 - val_loss: 0.4454 - val_acc: 0.7917 - val_recall: 1.0000\n",
      "Epoch 5/40\n",
      "45/45 [==============================] - 148s 3s/step - loss: 0.3105 - acc: 0.8666 - recall: 0.7703 - val_loss: 0.4134 - val_acc: 0.7917 - val_recall: 0.7361\n",
      "Epoch 6/40\n",
      "45/45 [==============================] - 149s 3s/step - loss: 0.3109 - acc: 0.9222 - recall: 0.7111 - val_loss: 0.3518 - val_acc: 0.8333 - val_recall: 0.9167\n",
      "Epoch 7/40\n",
      "45/45 [==============================] - 147s 3s/step - loss: 0.1676 - acc: 0.9222 - recall: 0.6776 - val_loss: 0.3030 - val_acc: 0.9167 - val_recall: 0.8889\n",
      "Epoch 8/40\n",
      "45/45 [==============================] - 147s 3s/step - loss: 0.3166 - acc: 0.9389 - recall: 0.8630 - val_loss: 0.1618 - val_acc: 0.8958 - val_recall: 0.8194\n",
      "Epoch 9/40\n",
      "45/45 [==============================] - 144s 3s/step - loss: 0.1379 - acc: 0.9390 - recall: 0.7372 - val_loss: 0.2459 - val_acc: 0.8750 - val_recall: 0.8472\n",
      "Epoch 10/40\n",
      "45/45 [==============================] - 147s 3s/step - loss: 0.1693 - acc: 0.9556 - recall: 0.7667 - val_loss: 0.2671 - val_acc: 0.8958 - val_recall: 0.9583\n",
      "Epoch 11/40\n",
      "45/45 [==============================] - 144s 3s/step - loss: 0.2010 - acc: 0.9667 - recall: 0.7890 - val_loss: 0.1534 - val_acc: 0.9583 - val_recall: 0.7917\n",
      "Epoch 12/40\n",
      "45/45 [==============================] - 148s 3s/step - loss: 0.3833 - acc: 0.9500 - recall: 0.7224 - val_loss: 0.4054 - val_acc: 0.8958 - val_recall: 0.8958\n",
      "Epoch 13/40\n",
      "45/45 [==============================] - 151s 3s/step - loss: 0.0821 - acc: 0.9778 - recall: 0.7594 - val_loss: 0.2279 - val_acc: 0.8958 - val_recall: 1.0000\n",
      "Epoch 14/40\n",
      "45/45 [==============================] - 158s 4s/step - loss: 0.0906 - acc: 0.9611 - recall: 0.7296 - val_loss: 0.2507 - val_acc: 0.8542 - val_recall: 0.7639\n",
      "Epoch 15/40\n",
      "45/45 [==============================] - 153s 3s/step - loss: 0.1210 - acc: 0.9667 - recall: 0.8222 - val_loss: 0.4169 - val_acc: 0.8958 - val_recall: 0.8194\n",
      "Epoch 16/40\n",
      "45/45 [==============================] - 152s 3s/step - loss: 0.0461 - acc: 0.9889 - recall: 0.8481 - val_loss: 0.2856 - val_acc: 0.9375 - val_recall: 0.8750\n",
      "Epoch 17/40\n",
      "45/45 [==============================] - 150s 3s/step - loss: 0.1380 - acc: 0.9667 - recall: 0.7039 - val_loss: 0.2206 - val_acc: 0.9375 - val_recall: 0.8333\n",
      "Epoch 18/40\n",
      "45/45 [==============================] - 146s 3s/step - loss: 0.0691 - acc: 0.9833 - recall: 0.7036 - val_loss: 0.4375 - val_acc: 0.9375 - val_recall: 0.8889\n",
      "Epoch 19/40\n",
      "45/45 [==============================] - 144s 3s/step - loss: 0.0271 - acc: 0.9889 - recall: 0.7930 - val_loss: 0.1159 - val_acc: 0.9583 - val_recall: 0.8056\n",
      "Epoch 20/40\n",
      "45/45 [==============================] - 147s 3s/step - loss: 0.1097 - acc: 0.9722 - recall: 0.7667 - val_loss: 0.5661 - val_acc: 0.9375 - val_recall: 0.7917\n",
      "Epoch 21/40\n",
      "45/45 [==============================] - 144s 3s/step - loss: 0.0359 - acc: 0.9944 - recall: 0.7927 - val_loss: 0.1034 - val_acc: 0.9583 - val_recall: 0.7917\n",
      "Epoch 22/40\n",
      "45/45 [==============================] - 143s 3s/step - loss: 0.1088 - acc: 0.9889 - recall: 0.8222 - val_loss: 0.1135 - val_acc: 0.9583 - val_recall: 0.9722\n",
      "Epoch 23/40\n",
      "45/45 [==============================] - 144s 3s/step - loss: 0.0619 - acc: 0.9889 - recall: 0.9444 - val_loss: 0.1909 - val_acc: 0.9167 - val_recall: 0.8889\n",
      "Epoch 24/40\n",
      "45/45 [==============================] - 142s 3s/step - loss: 0.1952 - acc: 0.9722 - recall: 0.8592 - val_loss: 0.0693 - val_acc: 0.9583 - val_recall: 0.9167\n",
      "Epoch 25/40\n",
      "45/45 [==============================] - 143s 3s/step - loss: 3.6781 - acc: 0.7666 - recall: 0.3112 - val_loss: 7.3875 - val_acc: 0.5417 - val_recall: 0.0000e+00\n",
      "Epoch 26/40\n",
      "45/45 [==============================] - 142s 3s/step - loss: 5.1949 - acc: 0.6777 - recall: 0.0000e+00 - val_loss: 7.3875 - val_acc: 0.5417 - val_recall: 0.0000e+00\n",
      "Epoch 27/40\n",
      "45/45 [==============================] - 141s 3s/step - loss: 6.5360 - acc: 0.5945 - recall: 0.0000e+00 - val_loss: 7.3875 - val_acc: 0.5417 - val_recall: 0.0000e+00\n",
      "Epoch 28/40\n",
      "45/45 [==============================] - 144s 3s/step - loss: 5.6413 - acc: 0.6500 - recall: 0.0000e+00 - val_loss: 7.3875 - val_acc: 0.5417 - val_recall: 0.0000e+00\n",
      "Epoch 29/40\n",
      "45/45 [==============================] - 143s 3s/step - loss: 5.7323 - acc: 0.6444 - recall: 0.0000e+00 - val_loss: 7.3875 - val_acc: 0.5417 - val_recall: 0.0000e+00\n",
      "Epoch 30/40\n",
      "45/45 [==============================] - 143s 3s/step - loss: 6.7136 - acc: 0.5835 - recall: 0.0000e+00 - val_loss: 7.3875 - val_acc: 0.5417 - val_recall: 0.0000e+00\n",
      "Epoch 31/40\n",
      "45/45 [==============================] - 3681s 82s/step - loss: 5.2818 - acc: 0.6723 - recall: 0.0000e+00 - val_loss: 7.3875 - val_acc: 0.5417 - val_recall: 0.0000e+00\n",
      "Epoch 32/40\n",
      "45/45 [==============================] - 150s 3s/step - loss: 5.6413 - acc: 0.6500 - recall: 0.0000e+00 - val_loss: 7.3875 - val_acc: 0.5417 - val_recall: 0.0000e+00\n",
      "Epoch 33/40\n",
      "45/45 [==============================] - 148s 3s/step - loss: 6.1762 - acc: 0.6168 - recall: 0.0000e+00 - val_loss: 7.3875 - val_acc: 0.5417 - val_recall: 0.0000e+00\n",
      "Epoch 34/40\n",
      "45/45 [==============================] - 145s 3s/step - loss: 6.0886 - acc: 0.6223 - recall: 0.0000e+00 - val_loss: 7.3875 - val_acc: 0.5417 - val_recall: 0.0000e+00\n",
      "Epoch 35/40\n",
      "45/45 [==============================] - 144s 3s/step - loss: 5.6401 - acc: 0.6501 - recall: 0.0000e+00 - val_loss: 7.3875 - val_acc: 0.5417 - val_recall: 0.0000e+00\n",
      "Epoch 36/40\n",
      "45/45 [==============================] - 144s 3s/step - loss: 5.9995 - acc: 0.6278 - recall: 0.0000e+00 - val_loss: 7.3875 - val_acc: 0.5417 - val_recall: 0.0000e+00\n",
      "Epoch 37/40\n",
      "45/45 [==============================] - 142s 3s/step - loss: 5.9990 - acc: 0.6278 - recall: 0.0000e+00 - val_loss: 7.3875 - val_acc: 0.5417 - val_recall: 0.0000e+00\n",
      "Epoch 38/40\n",
      "45/45 [==============================] - 142s 3s/step - loss: 5.3720 - acc: 0.6667 - recall: 0.0000e+00 - val_loss: 7.3875 - val_acc: 0.5417 - val_recall: 0.0000e+00\n",
      "Epoch 39/40\n",
      "45/45 [==============================] - 147s 3s/step - loss: 5.8199 - acc: 0.6389 - recall: 0.0000e+00 - val_loss: 7.3875 - val_acc: 0.5417 - val_recall: 0.0000e+00\n",
      "Epoch 40/40\n",
      "45/45 [==============================] - 147s 3s/step - loss: 6.0905 - acc: 0.6221 - recall: 0.0000e+00 - val_loss: 7.3875 - val_acc: 0.5417 - val_recall: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "cfg_name = \"cfg1.txt\"\n",
    "d = create_dict_with_params(\"cfg/\" + cfg_name)\n",
    "test1 = main(cfg_name = cfg_name, **d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = create_generator(d[\"validation_data_dir\"], d[\"batch_size\"], d[\"img_width\"], d[\"img_height\"])\n",
    "a = list(zip(test.metrics_names, test.evaluate_generator(validation_generator, d[\"nb_validation_samples\"]/d[\"batch_size\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_logs(\"results\", \"log1\", \"cfg1.txt\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recall_threshold(threshold = 0.5):\n",
    "    def recall(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.clip(y_true, 0, 1))\n",
    "        recall_ratio = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall_ratio\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dict_with_params(path):\n",
    "    param_list = open(path, 'r').read().split('\\n')\n",
    "    param_list = list(map(lambda x: x.split(\" = \"), param_list))\n",
    "    d = {x[0]:x[1] for x in param_list}\n",
    "    int_params = ['batch_size', 'epochs', 'img_height', 'img_width',\n",
    "                  'nb_train_samples', 'nb_validation_samples']\n",
    "    for param in int_params:\n",
    "        d[param] = int(d[param])\n",
    "    d['without_augmentation'] = str_to_bool(d['without_augmentation'])\n",
    "    if not d['without_augmentation']:\n",
    "        gen_params = d['generator_params'][1:-1].split(\",\")\n",
    "        new_d = {}\n",
    "        for param in gen_params:\n",
    "            key, value = param.split(\" : \")\n",
    "            new_d[key.strip()] = value\n",
    "        gen_float_params  = ['height_shift_range', 'rotation_range',\n",
    "                             'shear_range', 'width_shift_range', 'zoom_range']\n",
    "        for param in gen_float_params:\n",
    "            new_d[param] = float(new_d[param])\n",
    "        new_d['horizontal_flip'] = str_to_bool(new_d['horizontal_flip'])\n",
    "        d['generator_params'] = new_d\n",
    "    return d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
